#!/usr/bin/env python3
"""
Generate pre-computed RGB→Spectra6 color lookup table at build time.

This eliminates runtime LUT generation cost by computing the table
during compilation and storing it in flash (PROGMEM).

The LUT uses Lab color space for perceptually accurate color matching,
identical to the runtime algorithm.

Size vs Precision tradeoff:
  4 bits = 16x16x16 =   4KB (may show banding)
  5 bits = 32x32x32 =  32KB (recommended)
  6 bits = 64x64x64 = 256KB (overkill for 6-color output)

Usage:
    python generate_color_lut.py [output_file] [--bits N]
    
Examples:
    python generate_color_lut.py lib/EL133UF1/EL133UF1_ColorLUT.h
    python generate_color_lut.py lib/EL133UF1/EL133UF1_ColorLUT.h --bits 4  # 4KB LUT
"""

import math
import sys
import os
import argparse

# Default LUT configuration - can be overridden via --bits argument
DEFAULT_COLOR_LUT_BITS = 5

# Spectra 6 color codes (must match EL133UF1.h)
EL133UF1_BLACK = 0
EL133UF1_WHITE = 1
EL133UF1_YELLOW = 2
EL133UF1_RED = 3
EL133UF1_BLUE = 5
EL133UF1_GREEN = 6

SPECTRA_CODE = [
    EL133UF1_BLACK,
    EL133UF1_WHITE,
    EL133UF1_YELLOW,
    EL133UF1_RED,
    EL133UF1_BLUE,
    EL133UF1_GREEN
]

# Default calibrated Spectra 6 palette (RGB values)
# Must match useDefaultPalette() in EL133UF1_Color.cpp
DEFAULT_PALETTE = [
    (10, 10, 10),       # Black
    (245, 245, 235),    # White (slightly warm)
    (245, 210, 50),     # Yellow
    (190, 60, 55),      # Red (brick/tomato)
    (45, 75, 160),      # Blue (navy)
    (55, 140, 85),      # Green (teal/forest)
]

# Pre-computed sRGB to linear LUT
srgb_to_linear = []
for i in range(256):
    v = i / 255.0
    if v > 0.04045:
        srgb_to_linear.append(((v + 0.055) / 1.055) ** 2.4)
    else:
        srgb_to_linear.append(v / 12.92)


def rgb_to_lab(r, g, b):
    """Convert RGB to CIE Lab color space."""
    # sRGB to linear RGB
    rf = srgb_to_linear[r]
    gf = srgb_to_linear[g]
    bf = srgb_to_linear[b]
    
    # Linear RGB to XYZ
    x = rf * 0.4124564 + gf * 0.3575761 + bf * 0.1804375
    y = rf * 0.2126729 + gf * 0.7151522 + bf * 0.0721750
    z = rf * 0.0193339 + gf * 0.1191920 + bf * 0.9503041
    
    # Normalize for D65 white point
    x /= 0.95047
    y /= 1.00000
    z /= 1.08883
    
    # XYZ to Lab
    epsilon = 0.008856
    kappa = 903.3
    
    fx = x ** (1/3) if x > epsilon else (kappa * x + 16.0) / 116.0
    fy = y ** (1/3) if y > epsilon else (kappa * y + 16.0) / 116.0
    fz = z ** (1/3) if z > epsilon else (kappa * z + 16.0) / 116.0
    
    L = 116.0 * fy - 16.0
    a = 500.0 * (fx - fy)
    lab_b = 200.0 * (fy - fz)
    
    return (L, a, lab_b)


def find_nearest_lab(r, g, b, palette_lab):
    """Find nearest palette color using Lab color space."""
    L, a, lab_b = rgb_to_lab(r, g, b)
    
    min_dist = float('inf')
    best_idx = 1  # Default to white
    
    for i, (pL, pa, pb) in enumerate(palette_lab):
        # CIE76 Delta E (Euclidean distance in Lab space)
        dL = L - pL
        da = a - pa
        db = lab_b - pb
        dist = dL * dL + da * da + db * db
        
        if dist < min_dist:
            min_dist = dist
            best_idx = i
    
    return SPECTRA_CODE[best_idx]


def generate_lut(palette, bits):
    """Generate the complete RGB→Spectra LUT."""
    lut_size = 1 << bits
    lut_shift = 8 - bits
    
    # Pre-compute Lab values for palette
    palette_lab = [rgb_to_lab(r, g, b) for r, g, b in palette]
    
    lut = []
    
    for ri in range(lut_size):
        # Expand N-bit to 8-bit with proper rounding
        r = (ri << lut_shift) | (ri >> (bits - lut_shift)) if bits > lut_shift else (ri << lut_shift)
        for gi in range(lut_size):
            g = (gi << lut_shift) | (gi >> (bits - lut_shift)) if bits > lut_shift else (gi << lut_shift)
            for bi in range(lut_size):
                b = (bi << lut_shift) | (bi >> (bits - lut_shift)) if bits > lut_shift else (bi << lut_shift)
                color = find_nearest_lab(r, g, b, palette_lab)
                lut.append(color)
    
    return lut


def format_lut_as_c_header(lut, bits):
    """Format LUT as a C header file."""
    lut_size = 1 << bits
    size_kb = len(lut) / 1024
    
    lines = []
    lines.append("/**")
    lines.append(" * @file EL133UF1_ColorLUT.h")
    lines.append(" * @brief Pre-computed RGB→Spectra6 color lookup table")
    lines.append(" * ")
    lines.append(" * AUTO-GENERATED FILE - DO NOT EDIT MANUALLY")
    lines.append(" * Generated by: scripts/generate_color_lut.py")
    lines.append(" * ")
    lines.append(f" * This LUT maps {bits}-bit-per-channel RGB values to Spectra 6 colors")
    lines.append(" * using CIE Lab perceptual color matching.")
    lines.append(" * ")
    lines.append(f" * Size: {len(lut)} bytes ({size_kb:.0f}KB) = {lut_size}x{lut_size}x{lut_size}")
    lines.append(f" * Bits per channel: {bits}")
    lines.append(" */")
    lines.append("")
    lines.append("#ifndef EL133UF1_COLORLUT_H")
    lines.append("#define EL133UF1_COLORLUT_H")
    lines.append("")
    lines.append("#include <Arduino.h>")
    lines.append("")
    lines.append(f"// Verify LUT configuration matches (must define COLOR_LUT_BITS={bits} or use default)")
    lines.append(f"#if defined(COLOR_LUT_BITS) && COLOR_LUT_BITS != {bits}")
    lines.append(f'#error "COLOR_LUT_BITS mismatch: header generated with {bits} bits, code expects different value. Regenerate with: python scripts/generate_color_lut.py --bits $COLOR_LUT_BITS"')
    lines.append("#endif")
    lines.append("")
    lines.append("// Store in flash (PROGMEM) to save RAM")
    lines.append(f"static const uint8_t PROGMEM SPECTRA6_COLOR_LUT[{len(lut)}] = {{")
    
    # Format data in rows of 32 values
    for i in range(0, len(lut), 32):
        chunk = lut[i:i+32]
        line = "    " + ", ".join(f"{v}" for v in chunk) + ","
        lines.append(line)
    
    lines.append("};")
    lines.append("")
    lines.append("#endif // EL133UF1_COLORLUT_H")
    
    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(
        description='Generate RGB→Spectra6 color lookup table',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Size vs Precision:
  --bits 4:  4KB LUT (16x16x16) - smallest, may show banding
  --bits 5: 32KB LUT (32x32x32) - recommended balance
  --bits 6: 256KB LUT (64x64x64) - overkill for 6 colors
        """
    )
    parser.add_argument('output', nargs='?', default=None,
                        help='Output file path (default: stdout)')
    parser.add_argument('--bits', type=int, default=DEFAULT_COLOR_LUT_BITS,
                        choices=[4, 5, 6],
                        help=f'Bits per channel (default: {DEFAULT_COLOR_LUT_BITS})')
    
    args = parser.parse_args()
    
    bits = args.bits
    lut_size = 1 << bits
    total_entries = lut_size ** 3
    size_kb = total_entries / 1024
    
    print(f"Generating {lut_size}x{lut_size}x{lut_size} color LUT ({size_kb:.0f}KB)...", file=sys.stderr)
    lut = generate_lut(DEFAULT_PALETTE, bits)
    print(f"Generated {len(lut)} entries", file=sys.stderr)
    
    # Output as C header
    header = format_lut_as_c_header(lut, bits)
    
    # Write to file or stdout
    if args.output:
        with open(args.output, 'w') as f:
            f.write(header)
        print(f"Written to {args.output}", file=sys.stderr)
    else:
        print(header)


if __name__ == "__main__":
    main()
